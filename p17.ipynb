{"cells":[{"cell_type":"markdown","metadata":{"id":"g69IHs1lIhXx"},"source":["The next thing we'll do is to create a melody as midi. A melody with 1000 notes. We'll extend this when we want more data, but at the moment this corresponds to 2 generated songs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1753552900225,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"MwzDkeOPEfkl","outputId":"af6a1207-ee5e-46c3-8136-f2c337c34683"},"outputs":[{"name":"stdout","output_type":"stream","text":["🎵 Saved as melody.mid\n"]}],"source":["from midiutil import MIDIFile\n","import random\n","\n","# === Helper Functions ===\n","def get_minor_scale_with_octaves(root_midi):\n","    \"\"\"Return natural minor scale in octaves 3, 4, and 5.\"\"\"\n","    intervals = [0, 2, 3, 5, 7, 8, 10]\n","    base = [root_midi + i for i in intervals]\n","    return base + [n - 12 for n in base] + [n + 12 for n in base]\n","\n","# === CONFIG ===\n","mf = MIDIFile(1)\n","track = 0\n","channel = 0\n","volume = 100\n","default_tempo = 120\n","mf.addTempo(track, 0, default_tempo)\n","\n","durations = [0.25, 0.5, 1, 2]\n","current_time = 0\n","three_minutes_beats = 3 * default_tempo\n","\n","# === Initialize first key and tempo\n","current_tempo = default_tempo\n","current_root = 59  # B3\n","current_scale = get_minor_scale_with_octaves(current_root)\n","mf.addTempo(track, current_time, current_tempo)\n","\n","# === Melody Generation ===\n","last_pitch = random.choice(current_scale)  # start with any note\n","note_count = 0\n","\n","while note_count < 2000:\n","    duration = random.choice(durations)\n","\n","    # Style switch if 3 minutes of MIDI time (in beats) have passed\n","    if current_time >= three_minutes_beats:\n","        current_time = round(current_time, 2)\n","        current_tempo = random.randint(20, 200)\n","        current_root = random.randint(48, 72)\n","        current_scale = get_minor_scale_with_octaves(current_root)\n","        mf.addTempo(track, current_time, current_tempo)\n","        three_minutes_beats = current_time + 3 * current_tempo\n","\n","    # Filter notes within ±7 semitones of last pitch\n","    candidates = [p for p in current_scale if abs(p - last_pitch) <= 7]\n","    if not candidates:\n","        candidates = [last_pitch]  # fallback in case of no valid options\n","\n","    pitch = random.choice(candidates)\n","\n","    # Optional tied note\n","    if random.random() < 0.3:\n","        tie = random.choice(durations)\n","        duration += tie\n","\n","    mf.addNote(track, channel, pitch, current_time, duration, volume)\n","    current_time += duration\n","    last_pitch = pitch\n","    note_count += 1\n","\n","# === Save MIDI\n","with open(\"melody.mid\", \"wb\") as f:\n","    mf.writeFile(f)\n","\n","print(\"🎵 Saved as melody.mid\")"]},{"cell_type":"markdown","metadata":{"id":"3Kvl4karLCPV"},"source":["Now we have both lyrics and a melody. In this step we want to combine them together to create the training data. For now we're just doing the rhythm. We're still working on adding pitch correctly. But except for pitch we can extend the data to be as much as we like and the step after the next we actually train the ai."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11244,"status":"ok","timestamp":1753552915181,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"HawVqNaDLZy0","outputId":"7684a52f-7f2c-4185-dfe7-8c64f132aa42"},"outputs":[{"name":"stdout","output_type":"stream","text":["🎵 Loading MIDI file: melody.mid\n","🎹 MIDI loaded. Total duration: 0.30 hours\n","📝 Preparing blank WAV file: melody.wav\n","🎶 Processing note 1: Pitch 54, Time 0.00s → 1.25s\n","🎶 Processing note 101: Pitch 78, Time 70.62s → 71.62s\n","🎶 Processing note 201: Pitch 71, Time 138.00s → 138.62s\n","🎶 Processing note 301: Pitch 52, Time 202.86s → 203.35s\n","🎶 Processing note 401: Pitch 55, Time 260.69s → 261.65s\n","🎶 Processing note 501: Pitch 60, Time 320.56s → 320.81s\n","🎶 Processing note 601: Pitch 43, Time 369.71s → 370.42s\n","🎶 Processing note 701: Pitch 43, Time 406.05s → 406.13s\n","🎶 Processing note 801: Pitch 71, Time 448.99s → 449.71s\n","🎶 Processing note 901: Pitch 59, Time 500.15s → 500.24s\n","🎶 Processing note 1001: Pitch 67, Time 548.36s → 548.54s\n","🎶 Processing note 1101: Pitch 66, Time 594.24s → 594.42s\n","🎶 Processing note 1201: Pitch 81, Time 636.16s → 636.33s\n","🎶 Processing note 1301: Pitch 83, Time 680.10s → 680.36s\n","🎶 Processing note 1401: Pitch 77, Time 723.49s → 723.62s\n","🎶 Processing note 1501: Pitch 58, Time 787.97s → 788.49s\n","🎶 Processing note 1601: Pitch 75, Time 858.10s → 858.62s\n","🎶 Processing note 1701: Pitch 70, Time 918.96s → 919.35s\n","🎶 Processing note 1801: Pitch 51, Time 968.13s → 968.51s\n","🎶 Processing note 1901: Pitch 73, Time 1019.90s → 1020.00s\n","✅ Synthesis complete. 2000 notes written to: melody.wav\n","📏 Normalizing audio...\n","✅ Normalization done.\n","🔄 Converting to MP3: melody.mp3\n","🧹 Removing intermediate WAV file: melody.wav\n","🎉 Done! MP3 saved to: melody.mp3\n"]}],"source":["\n","import os\n","import numpy as np\n","import pretty_midi\n","import soundfile as sf\n","import subprocess\n","from IPython.display import clear_output\n","import librosa\n","\n","# === CONFIG ===\n","midi_path = \"melody.mid\"\n","output_path = \"melody.mp3\"\n","wav_path = output_path.replace(\".mp3\", \".wav\")\n","sr = 22050\n","\n","# Prevent tick errors in long MIDI files\n","pretty_midi.pretty_midi.MAX_TICK = 1e10\n","\n","# === Helpers ===\n","def midi_to_freq(midi_note):\n","    return 440.0 * (2 ** ((midi_note - 69) / 12))\n","\n","def generate_sine_with_vibrato(freq, duration_sec, sr=22050, vibrato_freq=5, vibrato_depth=1):\n","    t = np.linspace(0, duration_sec, int(sr * duration_sec), False)\n","    phase = 2 * np.pi * freq * t + np.sin(2 * np.pi * vibrato_freq * t) * vibrato_depth\n","    wave = np.sin(phase)\n","    fade_samples = int(0.02 * sr)\n","    envelope = np.ones_like(wave)\n","    envelope[:fade_samples] = np.linspace(0, 1, fade_samples)\n","    envelope[-fade_samples:] = np.linspace(1, 0, fade_samples)\n","    return wave * envelope\n","\n","# === Load MIDI ===\n","print(f\"🎵 Loading MIDI file: {midi_path}\")\n","midi_data = pretty_midi.PrettyMIDI(midi_path)\n","duration_sec = midi_data.get_end_time() + 1\n","print(f\"🎹 MIDI loaded. Total duration: {duration_sec / 3600:.2f} hours\")\n","\n","# === Create empty WAV file ===\n","print(f\"📝 Preparing blank WAV file: {wav_path}\")\n","with sf.SoundFile(wav_path, mode='w', samplerate=sr, channels=1, subtype='PCM_16') as f:\n","    pass  # file initialized\n","\n","# === Stream audio note by note ===\n","note_count = 0\n","for instrument in midi_data.instruments:\n","    for idx, note in enumerate(instrument.notes):\n","        note_count += 1  # <- this was missing\n","\n","        if note_count % 100 == 1:\n","            #clear_output(wait=True)\n","            print(f\"🎶 Processing note {note_count}: Pitch {note.pitch}, Time {note.start:.2f}s → {note.end:.2f}s\")\n","\n","        freq = midi_to_freq(note.pitch)\n","        duration = note.end - note.start\n","        start_sample = int(note.start * sr)\n","\n","        sine_wave = generate_sine_with_vibrato(freq, duration, sr=sr)\n","\n","        with sf.SoundFile(wav_path, mode='r+') as f:\n","            current_frames = f.frames\n","\n","            if start_sample > current_frames:\n","                silence = np.zeros(start_sample - current_frames)\n","                f.seek(0, sf.SEEK_END)\n","                f.write(silence)\n","\n","            f.seek(0, sf.SEEK_END)\n","            f.write(sine_wave)\n","\n","print(f\"✅ Synthesis complete. {note_count} notes written to: {wav_path}\")\n","\n","# === Normalize ===\n","print(\"📏 Normalizing audio...\")\n","y, _ = librosa.load(wav_path, sr=sr)\n","y = y / np.max(np.abs(y))\n","sf.write(wav_path, y, sr)\n","print(\"✅ Normalization done.\")\n","\n","# === Convert to MP3 ===\n","print(f\"🔄 Converting to MP3: {output_path}\")\n","subprocess.call([\"ffmpeg\", \"-y\", \"-i\", wav_path, output_path])\n","\n","# === Clean up ===\n","print(f\"🧹 Removing intermediate WAV file: {wav_path}\")\n","os.remove(wav_path)\n","\n","print(f\"🎉 Done! MP3 saved to: {output_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1753552917702,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"-DkE1S71ag0H","outputId":"44f2fc21-e475-4e1a-d8a5-4abdf9aa134d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","✅ Done! Extracted 2000 onsets from melody.mid.\n","🎧 Audio file: melody.mp3\n","📄 Onset labels saved to: onsets.txt (in seconds)\n","🧠 You can now use this for training your onset detection model.\n"]}],"source":["midi = pretty_midi.PrettyMIDI(\"melody.mid\")\n","onset_times = []\n","\n","for inst in midi.instruments:\n","    if inst.is_drum:\n","        continue\n","    for note in inst.notes:\n","        onset_times.append(note.start)  # start time in SECONDS, with tempo applied\n","\n","# Save to file\n","with open(\"onsets.txt\", \"w\") as f:\n","    for t in sorted(onset_times):\n","        f.write(f\"{t:.6f}\\n\")\n","\n","print(f\"\\n✅ Done! Extracted {len(onset_times)} onsets from melody.mid.\")\n","print(\"🎧 Audio file: melody.mp3\")\n","print(\"📄 Onset labels saved to: onsets.txt (in seconds)\")\n","print(\"🧠 You can now use this for training your onset detection model.\")"]},{"cell_type":"markdown","metadata":{"id":"Ag8e2ryOUT1_"},"source":["This is the part where we actually train the ai to eventually become very good at onset detection."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKS-FTvZMdjM","outputId":"76ff7480-913b-4a47-f071-fc1f7ada4224"},"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Starting training...\n","📘 Epoch 1/20000000\n","✅ Avg Loss: 0.631828 | 🎯 F1 Score (±40ms): 0.0000\n","📘 Epoch 2/20000000\n","✅ Avg Loss: 0.382571 | 🎯 F1 Score (±40ms): 0.0000\n","📘 Epoch 3/20000000\n","✅ Avg Loss: 0.380891 | 🎯 F1 Score (±40ms): 0.0000\n","📘 Epoch 4/20000000\n","✅ Avg Loss: 0.376295 | 🎯 F1 Score (±40ms): 0.0000\n","📘 Epoch 5/20000000\n","✅ Avg Loss: 0.375688 | 🎯 F1 Score (±40ms): 0.0000\n","📘 Epoch 6/20000000\n"]}],"source":["\n","import librosa\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","\n","# === CONFIG ===\n","AUDIO_PATH = \"melody.mp3\"\n","LABEL_PATH = \"onsets.txt\"\n","SR = 22050\n","HOP_LENGTH = 512\n","N_MELS = 32\n","CONTEXT = 7\n","EPOCHS = 20000000\n","BATCH_SIZE = 64\n","LR = 1e-2\n","TOLERANCE = 0.04  # seconds\n","\n","# === Load audio and extract features ===\n","y, sr = librosa.load(AUDIO_PATH, sr=SR)\n","S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, hop_length=HOP_LENGTH)\n","log_S = librosa.power_to_db(S, ref=np.max).T\n","\n","# === Load onset labels ===\n","onsets = np.array([float(l.strip()) for l in open(LABEL_PATH) if l.strip()])\n","onset_frames = librosa.time_to_frames(onsets, sr=sr, hop_length=HOP_LENGTH)\n","labels = np.zeros(log_S.shape[0])\n","for f in onset_frames:\n","    start = max(0, f - int(TOLERANCE * sr / HOP_LENGTH))\n","    end = min(len(labels), f + int(TOLERANCE * sr / HOP_LENGTH) + 1)\n","    labels[start:end] = 1\n","\n","# === Dataset ===\n","class OnsetDataset(Dataset):\n","    def __init__(self, X, y, context):\n","        self.X = X\n","        self.y = y\n","        self.context = context\n","\n","    def __len__(self):\n","        return len(self.X) - 2 * self.context\n","\n","    def __getitem__(self, idx):\n","        i = idx + self.context\n","        x = self.X[i - self.context:i + self.context + 1].T\n","        x = np.expand_dims(x, 0)  # [1, mel, time]\n","        return torch.tensor(x, dtype=torch.float32), torch.tensor(self.y[i], dtype=torch.float32)\n","\n","# === Smaller CNN ===\n","class SmallOnsetCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=(3, 3), padding=1),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d((1, 1)),\n","            nn.Flatten(),\n","            nn.Linear(16, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# === Train ===\n","dataset = OnsetDataset(log_S, labels, CONTEXT)\n","loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = SmallOnsetCNN().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=LR)\n","loss_fn = nn.BCELoss()\n","\n","from sklearn.metrics import precision_score, recall_score\n","import librosa\n","import numpy as np\n","import torch\n","\n","# === Load correct onset times once (as floats in seconds) ===\n","with open(\"evaluateonsets.txt\") as f:\n","    correct_onsets = np.array([\n","        float(line.strip())\n","        for line in f if line.strip() != ''\n","    ])\n","\n","# === F1 Scoring Function with Time Tolerance ===\n","def tolerant_f1(model, log_S, correct_onsets, context, device, sr, hop_length, threshold=0.5, tolerance=0.05):\n","    model.eval()\n","    X = []\n","    frame_times = []\n","\n","    for i in range(context, len(log_S) - context):\n","        segment = log_S[i - context:i + context + 1].T\n","        X.append(np.expand_dims(segment, 0))\n","        frame_time = librosa.frames_to_time(i, sr=sr, hop_length=hop_length)\n","        frame_times.append(frame_time)\n","\n","    X = torch.tensor(np.array(X), dtype=torch.float32).to(device)\n","    with torch.no_grad():\n","        preds = model(X).squeeze().cpu().numpy()\n","\n","    pred_times = [t for t, p in zip(frame_times, preds) if p >= threshold]\n","\n","    # === Match predictions to ground-truth with tolerance ===\n","    matched_pred = set()\n","    matched_true = set()\n","\n","    for i, true_onset in enumerate(correct_onsets):\n","        for j, pred_onset in enumerate(pred_times):\n","            if j in matched_pred:\n","                continue\n","            if abs(pred_onset - true_onset) <= tolerance:\n","                matched_true.add(i)\n","                matched_pred.add(j)\n","                break\n","\n","    tp = len(matched_true)\n","    fp = len(pred_times) - tp\n","    fn = len(correct_onsets) - tp\n","\n","    precision = tp / (tp + fp + 1e-8)\n","    recall = tp / (tp + fn + 1e-8)\n","    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n","\n","    return f1\n","\n","# === Training Loop ===\n","print(\"🚀 Starting training...\")\n","best_f1 = 0.0\n","loss_per_epoch = []\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    total_loss = 0\n","\n","    print(f\"📘 Epoch {epoch+1}/{EPOCHS}\")\n","    for batch_idx, (x, y) in enumerate(loader):\n","        x, y = x.to(device), y.to(device)\n","        pred = model(x).squeeze()\n","        loss = loss_fn(pred, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * x.size(0)\n","\n","    avg_loss = total_loss / len(dataset)\n","    loss_per_epoch.append(avg_loss)\n","\n","    # === Compute F1 Score using time-based onset matching ===\n","    f1 = tolerant_f1(model, log_S, correct_onsets, CONTEXT, device, SR, HOP_LENGTH)\n","\n","    if f1 > best_f1:\n","        best_f1 = f1\n","        print(f\"✅ Avg Loss: {avg_loss:.6f} | 🎯 New Best F1: {f1:.4f} 🏆\")\n","        # Save checkpoint\n","        model_path = f\"onset_model_epoch{epoch+1}.pth\"\n","        torch.save(model.state_dict(), model_path)\n","        print(f\"💾 Model saved: {model_path}\")\n","    else:\n","        print(f\"✅ Avg Loss: {avg_loss:.6f} | 🎯 F1 Score (±40ms): {f1:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":619},"executionInfo":{"elapsed":46160,"status":"error","timestamp":1753235108457,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"e-YbNe4sjU3h","outputId":"cd9a5357-7ec9-4356-8749-834cc6f42301"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4-3232997049.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfull_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_mp3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_audio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpreview_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_audio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpreview_duration_ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpreview_audio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreview_output_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_mp3\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_mp3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mp3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m                     p.returncode, p_err.decode(errors='ignore') ))\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0mfix_wav_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","# === PREVIEW CONFIG ===\n","input_audio_path = \"melody.mp3\"          # 👈 Your full audio file\n","preview_output_path = \"preview.mp3\"\n","preview_duration_ms = 10 * 60 * 1000     # 10 minutes\n","\n","# === CREATE PREVIEW ===\n","from pydub import AudioSegment\n","\n","full_audio = AudioSegment.from_mp3(input_audio_path)\n","preview_audio = full_audio[:preview_duration_ms]\n","preview_audio.export(preview_output_path, format=\"mp3\")\n","\n","print(f\"🎧 Preview saved to: {preview_output_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11392,"status":"ok","timestamp":1753548175096,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"_vUpZ2VyuSgG","outputId":"fe8f2f7a-1d17-40cd-892d-156ca29c569f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting midiutil\n","  Downloading MIDIUtil-1.2.1.tar.gz (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pretty_midi\n","  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (2.0.2)\n","Collecting mido>=1.1.16 (from pretty_midi)\n","  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty_midi) (25.0)\n","Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: midiutil, pretty_midi\n","  Building wheel for midiutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for midiutil: filename=MIDIUtil-1.2.1-py3-none-any.whl size=54569 sha256=837a53ea3e5851e16507480c0035a5d61c30c755f3b639976475e7a96ff934f3\n","  Stored in directory: /root/.cache/pip/wheels/6c/42/75/fce10c67f06fe627fad8acd1fd3a004a24e07b0f077761fbbd\n","  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592286 sha256=9e2caaa3584228ecb482dd9814b7d5006ab3146acea3fe3b9c5b2cdd2aa56b55\n","  Stored in directory: /root/.cache/pip/wheels/e6/95/ac/15ceaeb2823b04d8e638fd1495357adb8d26c00ccac9d7782e\n","Successfully built midiutil pretty_midi\n","Installing collected packages: midiutil, mido, pretty_midi\n","Successfully installed midiutil-1.2.1 mido-1.3.3 pretty_midi-0.2.10\n"]}],"source":["!pip install midiutil pretty_midi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":819,"status":"ok","timestamp":1753584378663,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"F75oplE-uOrA","outputId":"7d8f70ba-3dba-4785-f6ec-03dfded24e16"},"outputs":[{"name":"stdout","output_type":"stream","text":["🎯 Evaluation F1 Score (±50ms): 0.1218\n","   Precision: 0.0794 | Recall: 0.2612 | TP: 117, FP: 1356, FN: 331\n"]},{"data":{"text/plain":["0.12181155290324952"]},"execution_count":169,"metadata":{},"output_type":"execute_result"}],"source":["\n","import librosa\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","# === CONFIG ===\n","AUDIO_PATH = \"vocal.mp3\"\n","MODEL_PATH = \"Onset.pth\"\n","LABEL_PATH = \"evaluateonsets.txt\"\n","SR = 22050\n","HOP_LENGTH = 512\n","N_MELS = 32\n","CONTEXT = 7\n","THRESHOLD = 0.5\n","TOLERANCE = 0.05  # seconds\n","\n","# === Model Definition ===\n","class SmallOnsetCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=(3, 3), padding=1),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d((1, 1)),\n","            nn.Flatten(),\n","            nn.Linear(16, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# === Load model ===\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = SmallOnsetCNN().to(device)\n","model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n","model.eval()\n","\n","# === Load audio and features ===\n","y, sr = librosa.load(AUDIO_PATH, sr=SR)\n","S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, hop_length=HOP_LENGTH)\n","log_S = librosa.power_to_db(S, ref=np.max).T\n","\n","# === Load ground-truth onsets (in seconds) ===\n","with open(LABEL_PATH) as f:\n","    correct_onsets = np.array([float(line.strip()) for line in f if line.strip()])\n","\n","# === Evaluation Function ===\n","def tolerant_f1(model, log_S, correct_onsets, context, device, sr, hop_length, threshold=0.5, tolerance=0.05):\n","    model.eval()\n","    X = []\n","    frame_times = []\n","\n","    for i in range(context, len(log_S) - context):\n","        segment = log_S[i - context:i + context + 1].T\n","        X.append(np.expand_dims(segment, 0))\n","        frame_time = librosa.frames_to_time(i, sr=sr, hop_length=hop_length)\n","        frame_times.append(frame_time)\n","\n","    X = torch.tensor(np.array(X), dtype=torch.float32).to(device)\n","    with torch.no_grad():\n","        preds = model(X).squeeze().cpu().numpy()\n","\n","    pred_times = [t for t, p in zip(frame_times, preds) if p >= threshold]\n","\n","    matched_pred = set()\n","    matched_true = set()\n","\n","    for i, true_onset in enumerate(correct_onsets):\n","        for j, pred_onset in enumerate(pred_times):\n","            if j in matched_pred:\n","                continue\n","            if abs(pred_onset - true_onset) <= tolerance:\n","                matched_true.add(i)\n","                matched_pred.add(j)\n","                break\n","\n","    tp = len(matched_true)\n","    fp = len(pred_times) - tp\n","    fn = len(correct_onsets) - tp\n","\n","    precision = tp / (tp + fp + 1e-8)\n","    recall = tp / (tp + fn + 1e-8)\n","    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n","\n","    print(f\"🎯 Evaluation F1 Score (±{tolerance*1000:.0f}ms): {f1:.4f}\")\n","    print(f\"   Precision: {precision:.4f} | Recall: {recall:.4f} | TP: {tp}, FP: {fp}, FN: {fn}\")\n","    return f1\n","\n","# === Run Evaluation ===\n","tolerant_f1(model, log_S, correct_onsets, CONTEXT, device, SR, HOP_LENGTH, THRESHOLD, TOLERANCE)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO8MEl6BPdywZC+V5BhW29p"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}