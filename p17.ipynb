{"cells":[{"cell_type":"markdown","metadata":{"id":"g69IHs1lIhXx"},"source":["The next thing we'll do is to create a melody as midi. A melody with 1000 notes. We'll extend this when we want more data, but at the moment this corresponds to 2 generated songs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1753552900225,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"MwzDkeOPEfkl","outputId":"af6a1207-ee5e-46c3-8136-f2c337c34683"},"outputs":[{"name":"stdout","output_type":"stream","text":["üéµ Saved as melody.mid\n"]}],"source":["from midiutil import MIDIFile\n","import random\n","\n","# === Helper Functions ===\n","def get_minor_scale_with_octaves(root_midi):\n","    \"\"\"Return natural minor scale in octaves 3, 4, and 5.\"\"\"\n","    intervals = [0, 2, 3, 5, 7, 8, 10]\n","    base = [root_midi + i for i in intervals]\n","    return base + [n - 12 for n in base] + [n + 12 for n in base]\n","\n","# === CONFIG ===\n","mf = MIDIFile(1)\n","track = 0\n","channel = 0\n","volume = 100\n","default_tempo = 120\n","mf.addTempo(track, 0, default_tempo)\n","\n","durations = [0.25, 0.5, 1, 2]\n","current_time = 0\n","three_minutes_beats = 3 * default_tempo\n","\n","# === Initialize first key and tempo\n","current_tempo = default_tempo\n","current_root = 59  # B3\n","current_scale = get_minor_scale_with_octaves(current_root)\n","mf.addTempo(track, current_time, current_tempo)\n","\n","# === Melody Generation ===\n","last_pitch = random.choice(current_scale)  # start with any note\n","note_count = 0\n","\n","while note_count < 2000:\n","    duration = random.choice(durations)\n","\n","    # Style switch if 3 minutes of MIDI time (in beats) have passed\n","    if current_time >= three_minutes_beats:\n","        current_time = round(current_time, 2)\n","        current_tempo = random.randint(20, 200)\n","        current_root = random.randint(48, 72)\n","        current_scale = get_minor_scale_with_octaves(current_root)\n","        mf.addTempo(track, current_time, current_tempo)\n","        three_minutes_beats = current_time + 3 * current_tempo\n","\n","    # Filter notes within ¬±7 semitones of last pitch\n","    candidates = [p for p in current_scale if abs(p - last_pitch) <= 7]\n","    if not candidates:\n","        candidates = [last_pitch]  # fallback in case of no valid options\n","\n","    pitch = random.choice(candidates)\n","\n","    # Optional tied note\n","    if random.random() < 0.3:\n","        tie = random.choice(durations)\n","        duration += tie\n","\n","    mf.addNote(track, channel, pitch, current_time, duration, volume)\n","    current_time += duration\n","    last_pitch = pitch\n","    note_count += 1\n","\n","# === Save MIDI\n","with open(\"melody.mid\", \"wb\") as f:\n","    mf.writeFile(f)\n","\n","print(\"üéµ Saved as melody.mid\")"]},{"cell_type":"markdown","metadata":{"id":"3Kvl4karLCPV"},"source":["Now we have both lyrics and a melody. In this step we want to combine them together to create the training data. For now we're just doing the rhythm. We're still working on adding pitch correctly. But except for pitch we can extend the data to be as much as we like and the step after the next we actually train the ai."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11244,"status":"ok","timestamp":1753552915181,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"HawVqNaDLZy0","outputId":"7684a52f-7f2c-4185-dfe7-8c64f132aa42"},"outputs":[{"name":"stdout","output_type":"stream","text":["üéµ Loading MIDI file: melody.mid\n","üéπ MIDI loaded. Total duration: 0.30 hours\n","üìù Preparing blank WAV file: melody.wav\n","üé∂ Processing note 1: Pitch 54, Time 0.00s ‚Üí 1.25s\n","üé∂ Processing note 101: Pitch 78, Time 70.62s ‚Üí 71.62s\n","üé∂ Processing note 201: Pitch 71, Time 138.00s ‚Üí 138.62s\n","üé∂ Processing note 301: Pitch 52, Time 202.86s ‚Üí 203.35s\n","üé∂ Processing note 401: Pitch 55, Time 260.69s ‚Üí 261.65s\n","üé∂ Processing note 501: Pitch 60, Time 320.56s ‚Üí 320.81s\n","üé∂ Processing note 601: Pitch 43, Time 369.71s ‚Üí 370.42s\n","üé∂ Processing note 701: Pitch 43, Time 406.05s ‚Üí 406.13s\n","üé∂ Processing note 801: Pitch 71, Time 448.99s ‚Üí 449.71s\n","üé∂ Processing note 901: Pitch 59, Time 500.15s ‚Üí 500.24s\n","üé∂ Processing note 1001: Pitch 67, Time 548.36s ‚Üí 548.54s\n","üé∂ Processing note 1101: Pitch 66, Time 594.24s ‚Üí 594.42s\n","üé∂ Processing note 1201: Pitch 81, Time 636.16s ‚Üí 636.33s\n","üé∂ Processing note 1301: Pitch 83, Time 680.10s ‚Üí 680.36s\n","üé∂ Processing note 1401: Pitch 77, Time 723.49s ‚Üí 723.62s\n","üé∂ Processing note 1501: Pitch 58, Time 787.97s ‚Üí 788.49s\n","üé∂ Processing note 1601: Pitch 75, Time 858.10s ‚Üí 858.62s\n","üé∂ Processing note 1701: Pitch 70, Time 918.96s ‚Üí 919.35s\n","üé∂ Processing note 1801: Pitch 51, Time 968.13s ‚Üí 968.51s\n","üé∂ Processing note 1901: Pitch 73, Time 1019.90s ‚Üí 1020.00s\n","‚úÖ Synthesis complete. 2000 notes written to: melody.wav\n","üìè Normalizing audio...\n","‚úÖ Normalization done.\n","üîÑ Converting to MP3: melody.mp3\n","üßπ Removing intermediate WAV file: melody.wav\n","üéâ Done! MP3 saved to: melody.mp3\n"]}],"source":["\n","import os\n","import numpy as np\n","import pretty_midi\n","import soundfile as sf\n","import subprocess\n","from IPython.display import clear_output\n","import librosa\n","\n","# === CONFIG ===\n","midi_path = \"melody.mid\"\n","output_path = \"melody.mp3\"\n","wav_path = output_path.replace(\".mp3\", \".wav\")\n","sr = 22050\n","\n","# Prevent tick errors in long MIDI files\n","pretty_midi.pretty_midi.MAX_TICK = 1e10\n","\n","# === Helpers ===\n","def midi_to_freq(midi_note):\n","    return 440.0 * (2 ** ((midi_note - 69) / 12))\n","\n","def generate_sine_with_vibrato(freq, duration_sec, sr=22050, vibrato_freq=5, vibrato_depth=1):\n","    t = np.linspace(0, duration_sec, int(sr * duration_sec), False)\n","    phase = 2 * np.pi * freq * t + np.sin(2 * np.pi * vibrato_freq * t) * vibrato_depth\n","    wave = np.sin(phase)\n","    fade_samples = int(0.02 * sr)\n","    envelope = np.ones_like(wave)\n","    envelope[:fade_samples] = np.linspace(0, 1, fade_samples)\n","    envelope[-fade_samples:] = np.linspace(1, 0, fade_samples)\n","    return wave * envelope\n","\n","# === Load MIDI ===\n","print(f\"üéµ Loading MIDI file: {midi_path}\")\n","midi_data = pretty_midi.PrettyMIDI(midi_path)\n","duration_sec = midi_data.get_end_time() + 1\n","print(f\"üéπ MIDI loaded. Total duration: {duration_sec / 3600:.2f} hours\")\n","\n","# === Create empty WAV file ===\n","print(f\"üìù Preparing blank WAV file: {wav_path}\")\n","with sf.SoundFile(wav_path, mode='w', samplerate=sr, channels=1, subtype='PCM_16') as f:\n","    pass  # file initialized\n","\n","# === Stream audio note by note ===\n","note_count = 0\n","for instrument in midi_data.instruments:\n","    for idx, note in enumerate(instrument.notes):\n","        note_count += 1  # <- this was missing\n","\n","        if note_count % 100 == 1:\n","            #clear_output(wait=True)\n","            print(f\"üé∂ Processing note {note_count}: Pitch {note.pitch}, Time {note.start:.2f}s ‚Üí {note.end:.2f}s\")\n","\n","        freq = midi_to_freq(note.pitch)\n","        duration = note.end - note.start\n","        start_sample = int(note.start * sr)\n","\n","        sine_wave = generate_sine_with_vibrato(freq, duration, sr=sr)\n","\n","        with sf.SoundFile(wav_path, mode='r+') as f:\n","            current_frames = f.frames\n","\n","            if start_sample > current_frames:\n","                silence = np.zeros(start_sample - current_frames)\n","                f.seek(0, sf.SEEK_END)\n","                f.write(silence)\n","\n","            f.seek(0, sf.SEEK_END)\n","            f.write(sine_wave)\n","\n","print(f\"‚úÖ Synthesis complete. {note_count} notes written to: {wav_path}\")\n","\n","# === Normalize ===\n","print(\"üìè Normalizing audio...\")\n","y, _ = librosa.load(wav_path, sr=sr)\n","y = y / np.max(np.abs(y))\n","sf.write(wav_path, y, sr)\n","print(\"‚úÖ Normalization done.\")\n","\n","# === Convert to MP3 ===\n","print(f\"üîÑ Converting to MP3: {output_path}\")\n","subprocess.call([\"ffmpeg\", \"-y\", \"-i\", wav_path, output_path])\n","\n","# === Clean up ===\n","print(f\"üßπ Removing intermediate WAV file: {wav_path}\")\n","os.remove(wav_path)\n","\n","print(f\"üéâ Done! MP3 saved to: {output_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1753552917702,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"-DkE1S71ag0H","outputId":"44f2fc21-e475-4e1a-d8a5-4abdf9aa134d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","‚úÖ Done! Extracted 2000 onsets from melody.mid.\n","üéß Audio file: melody.mp3\n","üìÑ Onset labels saved to: onsets.txt (in seconds)\n","üß† You can now use this for training your onset detection model.\n"]}],"source":["midi = pretty_midi.PrettyMIDI(\"melody.mid\")\n","onset_times = []\n","\n","for inst in midi.instruments:\n","    if inst.is_drum:\n","        continue\n","    for note in inst.notes:\n","        onset_times.append(note.start)  # start time in SECONDS, with tempo applied\n","\n","# Save to file\n","with open(\"onsets.txt\", \"w\") as f:\n","    for t in sorted(onset_times):\n","        f.write(f\"{t:.6f}\\n\")\n","\n","print(f\"\\n‚úÖ Done! Extracted {len(onset_times)} onsets from melody.mid.\")\n","print(\"üéß Audio file: melody.mp3\")\n","print(\"üìÑ Onset labels saved to: onsets.txt (in seconds)\")\n","print(\"üß† You can now use this for training your onset detection model.\")"]},{"cell_type":"markdown","metadata":{"id":"Ag8e2ryOUT1_"},"source":["This is the part where we actually train the ai to eventually become very good at onset detection."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKS-FTvZMdjM","outputId":"76ff7480-913b-4a47-f071-fc1f7ada4224"},"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ Starting training...\n","üìò Epoch 1/20000000\n","‚úÖ Avg Loss: 0.631828 | üéØ F1 Score (¬±40ms): 0.0000\n","üìò Epoch 2/20000000\n","‚úÖ Avg Loss: 0.382571 | üéØ F1 Score (¬±40ms): 0.0000\n","üìò Epoch 3/20000000\n","‚úÖ Avg Loss: 0.380891 | üéØ F1 Score (¬±40ms): 0.0000\n","üìò Epoch 4/20000000\n","‚úÖ Avg Loss: 0.376295 | üéØ F1 Score (¬±40ms): 0.0000\n","üìò Epoch 5/20000000\n","‚úÖ Avg Loss: 0.375688 | üéØ F1 Score (¬±40ms): 0.0000\n","üìò Epoch 6/20000000\n"]}],"source":["\n","import librosa\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","\n","# === CONFIG ===\n","AUDIO_PATH = \"melody.mp3\"\n","LABEL_PATH = \"onsets.txt\"\n","SR = 22050\n","HOP_LENGTH = 512\n","N_MELS = 32\n","CONTEXT = 7\n","EPOCHS = 20000000\n","BATCH_SIZE = 64\n","LR = 1e-2\n","TOLERANCE = 0.04  # seconds\n","\n","# === Load audio and extract features ===\n","y, sr = librosa.load(AUDIO_PATH, sr=SR)\n","S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, hop_length=HOP_LENGTH)\n","log_S = librosa.power_to_db(S, ref=np.max).T\n","\n","# === Load onset labels ===\n","onsets = np.array([float(l.strip()) for l in open(LABEL_PATH) if l.strip()])\n","onset_frames = librosa.time_to_frames(onsets, sr=sr, hop_length=HOP_LENGTH)\n","labels = np.zeros(log_S.shape[0])\n","for f in onset_frames:\n","    start = max(0, f - int(TOLERANCE * sr / HOP_LENGTH))\n","    end = min(len(labels), f + int(TOLERANCE * sr / HOP_LENGTH) + 1)\n","    labels[start:end] = 1\n","\n","# === Dataset ===\n","class OnsetDataset(Dataset):\n","    def __init__(self, X, y, context):\n","        self.X = X\n","        self.y = y\n","        self.context = context\n","\n","    def __len__(self):\n","        return len(self.X) - 2 * self.context\n","\n","    def __getitem__(self, idx):\n","        i = idx + self.context\n","        x = self.X[i - self.context:i + self.context + 1].T\n","        x = np.expand_dims(x, 0)  # [1, mel, time]\n","        return torch.tensor(x, dtype=torch.float32), torch.tensor(self.y[i], dtype=torch.float32)\n","\n","# === Smaller CNN ===\n","class SmallOnsetCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=(3, 3), padding=1),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d((1, 1)),\n","            nn.Flatten(),\n","            nn.Linear(16, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# === Train ===\n","dataset = OnsetDataset(log_S, labels, CONTEXT)\n","loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = SmallOnsetCNN().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=LR)\n","loss_fn = nn.BCELoss()\n","\n","from sklearn.metrics import precision_score, recall_score\n","import librosa\n","import numpy as np\n","import torch\n","\n","# === Load correct onset times once (as floats in seconds) ===\n","with open(\"evaluateonsets.txt\") as f:\n","    correct_onsets = np.array([\n","        float(line.strip())\n","        for line in f if line.strip() != ''\n","    ])\n","\n","# === F1 Scoring Function with Time Tolerance ===\n","def tolerant_f1(model, log_S, correct_onsets, context, device, sr, hop_length, threshold=0.5, tolerance=0.05):\n","    model.eval()\n","    X = []\n","    frame_times = []\n","\n","    for i in range(context, len(log_S) - context):\n","        segment = log_S[i - context:i + context + 1].T\n","        X.append(np.expand_dims(segment, 0))\n","        frame_time = librosa.frames_to_time(i, sr=sr, hop_length=hop_length)\n","        frame_times.append(frame_time)\n","\n","    X = torch.tensor(np.array(X), dtype=torch.float32).to(device)\n","    with torch.no_grad():\n","        preds = model(X).squeeze().cpu().numpy()\n","\n","    pred_times = [t for t, p in zip(frame_times, preds) if p >= threshold]\n","\n","    # === Match predictions to ground-truth with tolerance ===\n","    matched_pred = set()\n","    matched_true = set()\n","\n","    for i, true_onset in enumerate(correct_onsets):\n","        for j, pred_onset in enumerate(pred_times):\n","            if j in matched_pred:\n","                continue\n","            if abs(pred_onset - true_onset) <= tolerance:\n","                matched_true.add(i)\n","                matched_pred.add(j)\n","                break\n","\n","    tp = len(matched_true)\n","    fp = len(pred_times) - tp\n","    fn = len(correct_onsets) - tp\n","\n","    precision = tp / (tp + fp + 1e-8)\n","    recall = tp / (tp + fn + 1e-8)\n","    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n","\n","    return f1\n","\n","# === Training Loop ===\n","print(\"üöÄ Starting training...\")\n","best_f1 = 0.0\n","loss_per_epoch = []\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    total_loss = 0\n","\n","    print(f\"üìò Epoch {epoch+1}/{EPOCHS}\")\n","    for batch_idx, (x, y) in enumerate(loader):\n","        x, y = x.to(device), y.to(device)\n","        pred = model(x).squeeze()\n","        loss = loss_fn(pred, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * x.size(0)\n","\n","    avg_loss = total_loss / len(dataset)\n","    loss_per_epoch.append(avg_loss)\n","\n","    # === Compute F1 Score using time-based onset matching ===\n","    f1 = tolerant_f1(model, log_S, correct_onsets, CONTEXT, device, SR, HOP_LENGTH)\n","\n","    if f1 > best_f1:\n","        best_f1 = f1\n","        print(f\"‚úÖ Avg Loss: {avg_loss:.6f} | üéØ New Best F1: {f1:.4f} üèÜ\")\n","        # Save checkpoint\n","        model_path = f\"onset_model_epoch{epoch+1}.pth\"\n","        torch.save(model.state_dict(), model_path)\n","        print(f\"üíæ Model saved: {model_path}\")\n","    else:\n","        print(f\"‚úÖ Avg Loss: {avg_loss:.6f} | üéØ F1 Score (¬±40ms): {f1:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":619},"executionInfo":{"elapsed":46160,"status":"error","timestamp":1753235108457,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"e-YbNe4sjU3h","outputId":"cd9a5357-7ec9-4356-8749-834cc6f42301"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4-3232997049.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfull_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_mp3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_audio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpreview_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_audio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpreview_duration_ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpreview_audio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreview_output_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_mp3\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_mp3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mp3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m                     p.returncode, p_err.decode(errors='ignore') ))\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0mfix_wav_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","# === PREVIEW CONFIG ===\n","input_audio_path = \"melody.mp3\"          # üëà Your full audio file\n","preview_output_path = \"preview.mp3\"\n","preview_duration_ms = 10 * 60 * 1000     # 10 minutes\n","\n","# === CREATE PREVIEW ===\n","from pydub import AudioSegment\n","\n","full_audio = AudioSegment.from_mp3(input_audio_path)\n","preview_audio = full_audio[:preview_duration_ms]\n","preview_audio.export(preview_output_path, format=\"mp3\")\n","\n","print(f\"üéß Preview saved to: {preview_output_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11392,"status":"ok","timestamp":1753548175096,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"_vUpZ2VyuSgG","outputId":"fe8f2f7a-1d17-40cd-892d-156ca29c569f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting midiutil\n","  Downloading MIDIUtil-1.2.1.tar.gz (1.0 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pretty_midi\n","  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (2.0.2)\n","Collecting mido>=1.1.16 (from pretty_midi)\n","  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty_midi) (25.0)\n","Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: midiutil, pretty_midi\n","  Building wheel for midiutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for midiutil: filename=MIDIUtil-1.2.1-py3-none-any.whl size=54569 sha256=837a53ea3e5851e16507480c0035a5d61c30c755f3b639976475e7a96ff934f3\n","  Stored in directory: /root/.cache/pip/wheels/6c/42/75/fce10c67f06fe627fad8acd1fd3a004a24e07b0f077761fbbd\n","  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592286 sha256=9e2caaa3584228ecb482dd9814b7d5006ab3146acea3fe3b9c5b2cdd2aa56b55\n","  Stored in directory: /root/.cache/pip/wheels/e6/95/ac/15ceaeb2823b04d8e638fd1495357adb8d26c00ccac9d7782e\n","Successfully built midiutil pretty_midi\n","Installing collected packages: midiutil, mido, pretty_midi\n","Successfully installed midiutil-1.2.1 mido-1.3.3 pretty_midi-0.2.10\n"]}],"source":["!pip install midiutil pretty_midi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":819,"status":"ok","timestamp":1753584378663,"user":{"displayName":"Clint Blocker","userId":"13741846383446494488"},"user_tz":-120},"id":"F75oplE-uOrA","outputId":"7d8f70ba-3dba-4785-f6ec-03dfded24e16"},"outputs":[{"name":"stdout","output_type":"stream","text":["üéØ Evaluation F1 Score (¬±50ms): 0.1218\n","   Precision: 0.0794 | Recall: 0.2612 | TP: 117, FP: 1356, FN: 331\n"]},{"data":{"text/plain":["0.12181155290324952"]},"execution_count":169,"metadata":{},"output_type":"execute_result"}],"source":["\n","import librosa\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","# === CONFIG ===\n","AUDIO_PATH = \"vocal.mp3\"\n","MODEL_PATH = \"Onset.pth\"\n","LABEL_PATH = \"evaluateonsets.txt\"\n","SR = 22050\n","HOP_LENGTH = 512\n","N_MELS = 32\n","CONTEXT = 7\n","THRESHOLD = 0.5\n","TOLERANCE = 0.05  # seconds\n","\n","# === Model Definition ===\n","class SmallOnsetCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=(3, 3), padding=1),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d((1, 1)),\n","            nn.Flatten(),\n","            nn.Linear(16, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# === Load model ===\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = SmallOnsetCNN().to(device)\n","model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n","model.eval()\n","\n","# === Load audio and features ===\n","y, sr = librosa.load(AUDIO_PATH, sr=SR)\n","S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, hop_length=HOP_LENGTH)\n","log_S = librosa.power_to_db(S, ref=np.max).T\n","\n","# === Load ground-truth onsets (in seconds) ===\n","with open(LABEL_PATH) as f:\n","    correct_onsets = np.array([float(line.strip()) for line in f if line.strip()])\n","\n","# === Evaluation Function ===\n","def tolerant_f1(model, log_S, correct_onsets, context, device, sr, hop_length, threshold=0.5, tolerance=0.05):\n","    model.eval()\n","    X = []\n","    frame_times = []\n","\n","    for i in range(context, len(log_S) - context):\n","        segment = log_S[i - context:i + context + 1].T\n","        X.append(np.expand_dims(segment, 0))\n","        frame_time = librosa.frames_to_time(i, sr=sr, hop_length=hop_length)\n","        frame_times.append(frame_time)\n","\n","    X = torch.tensor(np.array(X), dtype=torch.float32).to(device)\n","    with torch.no_grad():\n","        preds = model(X).squeeze().cpu().numpy()\n","\n","    pred_times = [t for t, p in zip(frame_times, preds) if p >= threshold]\n","\n","    matched_pred = set()\n","    matched_true = set()\n","\n","    for i, true_onset in enumerate(correct_onsets):\n","        for j, pred_onset in enumerate(pred_times):\n","            if j in matched_pred:\n","                continue\n","            if abs(pred_onset - true_onset) <= tolerance:\n","                matched_true.add(i)\n","                matched_pred.add(j)\n","                break\n","\n","    tp = len(matched_true)\n","    fp = len(pred_times) - tp\n","    fn = len(correct_onsets) - tp\n","\n","    precision = tp / (tp + fp + 1e-8)\n","    recall = tp / (tp + fn + 1e-8)\n","    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n","\n","    print(f\"üéØ Evaluation F1 Score (¬±{tolerance*1000:.0f}ms): {f1:.4f}\")\n","    print(f\"   Precision: {precision:.4f} | Recall: {recall:.4f} | TP: {tp}, FP: {fp}, FN: {fn}\")\n","    return f1\n","\n","# === Run Evaluation ===\n","tolerant_f1(model, log_S, correct_onsets, CONTEXT, device, SR, HOP_LENGTH, THRESHOLD, TOLERANCE)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO8MEl6BPdywZC+V5BhW29p"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}